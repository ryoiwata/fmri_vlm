{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88126d0-e0bd-47b6-afa8-74046447566d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2b29200-9c35-4e36-af0d-f76a7811efbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dat_file(filepath: str, delimiter: str = '\\t') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load a .dat file into a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the .dat file.\n",
    "        delimiter (str, optional): The delimiter used in the .dat file. \n",
    "                                   Default is tab ('\\\\t').\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The data from the .dat file as a NumPy array.\n",
    "    \"\"\"\n",
    "    # loadtxt will automatically infer rows/columns based on the file\n",
    "    data = np.loadtxt(filepath, delimiter=delimiter)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c47d573-ec96-4f33-8f4a-7ecd309e9c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_fisher_z(signals: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given time series data of shape (n_timepoints, n_regions),\n",
    "    compute the pairwise Pearson correlation among the columns (i.e., regions),\n",
    "    then apply the Fisher Z-transform to those correlation values.\n",
    "\n",
    "    Args:\n",
    "        signals (np.ndarray): fMRI time-series data of shape (n_timepoints, n_regions),\n",
    "                              where each column is a region, and each row is a timepoint.\n",
    "\n",
    "    Returns:\n",
    "        fisher_z_mat (np.ndarray): (n_regions, n_regions) matrix of\n",
    "                                   Fisher Z-transformed connectivity.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute Pearson correlation among columns (regions)\n",
    "    # rowvar=False => treat each column as a variable\n",
    "    corr_mat = np.corrcoef(signals, rowvar=False)  # shape: (n_regions, n_regions)\n",
    "\n",
    "    # Step 2: Apply Fisher Z-transform\n",
    "    # Z = arctanh(r), i.e. 0.5 * ln((1+r)/(1-r))\n",
    "    # We clamp r to avoid infinity at r=±1\n",
    "    epsilon = 1e-8\n",
    "    corr_mat = np.clip(corr_mat, -1 + epsilon, 1 - epsilon)\n",
    "    fisher_z_mat = np.arctanh(corr_mat)\n",
    "\n",
    "    return fisher_z_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e8d6dac-94dc-4e6f-98e1-e3dcda997f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abide_df = pd.read_csv(\"./Phenotypic_V1_0b.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbf92bc7-e66d-4f53-a67f-1db769003e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HANDEDNESS_CATEGORY</th>\n",
       "      <th>HANDEDNESS_SCORES</th>\n",
       "      <th>FIQ</th>\n",
       "      <th>...</th>\n",
       "      <th>WISC_IV_BLK_DSN_SCALED</th>\n",
       "      <th>WISC_IV_PIC_CON_SCALED</th>\n",
       "      <th>WISC_IV_MATRIX_SCALED</th>\n",
       "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
       "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
       "      <th>WISC_IV_CODING_SCALED</th>\n",
       "      <th>WISC_IV_SYM_SCALED</th>\n",
       "      <th>EYE_STATUS_AT_SCAN</th>\n",
       "      <th>AGE_AT_MPRAGE</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51456</td>\n",
       "      <td>Caltech_0051456</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51457</td>\n",
       "      <td>Caltech_0051457</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1</td>\n",
       "      <td>Ambi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51458</td>\n",
       "      <td>Caltech_0051458</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51459</td>\n",
       "      <td>Caltech_0051459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51460</td>\n",
       "      <td>Caltech_0051460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2</td>\n",
       "      <td>Ambi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SITE_ID  SUB_ID          FILE_ID  DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  SEX  \\\n",
       "0  CALTECH   51456  Caltech_0051456         1          4         55.4    1   \n",
       "1  CALTECH   51457  Caltech_0051457         1          4         22.9    1   \n",
       "2  CALTECH   51458  Caltech_0051458         1          1         39.2    1   \n",
       "3  CALTECH   51459  Caltech_0051459         1          1         22.8    1   \n",
       "4  CALTECH   51460  Caltech_0051460         1          1         34.6    2   \n",
       "\n",
       "  HANDEDNESS_CATEGORY  HANDEDNESS_SCORES    FIQ  ...  WISC_IV_BLK_DSN_SCALED  \\\n",
       "0                   R                NaN  126.0  ...                     NaN   \n",
       "1                Ambi                NaN  107.0  ...                     NaN   \n",
       "2                   R                NaN   93.0  ...                     NaN   \n",
       "3                   R                NaN  106.0  ...                     NaN   \n",
       "4                Ambi                NaN  133.0  ...                     NaN   \n",
       "\n",
       "   WISC_IV_PIC_CON_SCALED WISC_IV_MATRIX_SCALED WISC_IV_DIGIT_SPAN_SCALED  \\\n",
       "0                     NaN                   NaN                       NaN   \n",
       "1                     NaN                   NaN                       NaN   \n",
       "2                     NaN                   NaN                       NaN   \n",
       "3                     NaN                   NaN                       NaN   \n",
       "4                     NaN                   NaN                       NaN   \n",
       "\n",
       "  WISC_IV_LET_NUM_SCALED  WISC_IV_CODING_SCALED  WISC_IV_SYM_SCALED  \\\n",
       "0                    NaN                    NaN                 NaN   \n",
       "1                    NaN                    NaN                 NaN   \n",
       "2                    NaN                    NaN                 NaN   \n",
       "3                    NaN                    NaN                 NaN   \n",
       "4                    NaN                    NaN                 NaN   \n",
       "\n",
       "   EYE_STATUS_AT_SCAN  AGE_AT_MPRAGE  BMI  \n",
       "0                   2            NaN  NaN  \n",
       "1                   2            NaN  NaN  \n",
       "2                   2            NaN  NaN  \n",
       "3                   2            NaN  NaN  \n",
       "4                   2            NaN  NaN  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cc373be-7e9a-4203-9fc8-9a576d238ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SITE_ID', 'SUB_ID', 'FILE_ID', 'DX_GROUP', 'DSM_IV_TR', 'AGE_AT_SCAN',\n",
       "       'SEX', 'HANDEDNESS_CATEGORY', 'HANDEDNESS_SCORES', 'FIQ', 'VIQ', 'PIQ',\n",
       "       'FIQ_TEST_TYPE', 'VIQ_TEST_TYPE', 'PIQ_TEST_TYPE',\n",
       "       'ADI_R_SOCIAL_TOTAL_A', 'ADI_R_VERBAL_TOTAL_BV', 'ADI_RRB_TOTAL_C',\n",
       "       'ADI_R_ONSET_TOTAL_D', 'ADI_R_RSRCH_RELIABLE', 'ADOS_MODULE',\n",
       "       'ADOS_TOTAL', 'ADOS_COMM', 'ADOS_SOCIAL', 'ADOS_STEREO_BEHAV',\n",
       "       'ADOS_RSRCH_RELIABLE', 'ADOS_GOTHAM_SOCAFFECT', 'ADOS_GOTHAM_RRB',\n",
       "       'ADOS_GOTHAM_TOTAL', 'ADOS_GOTHAM_SEVERITY', 'SRS_VERSION',\n",
       "       'SRS_RAW_TOTAL', 'SRS_AWARENESS', 'SRS_COGNITION', 'SRS_COMMUNICATION',\n",
       "       'SRS_MOTIVATION', 'SRS_MANNERISMS', 'SCQ_TOTAL', 'AQ_TOTAL',\n",
       "       'COMORBIDITY', 'CURRENT_MED_STATUS', 'MEDICATION_NAME',\n",
       "       'OFF_STIMULANTS_AT_SCAN', 'VINELAND_RECEPTIVE_V_SCALED',\n",
       "       'VINELAND_EXPRESSIVE_V_SCALED', 'VINELAND_WRITTEN_V_SCALED',\n",
       "       'VINELAND_COMMUNICATION_STANDARD', 'VINELAND_PERSONAL_V_SCALED',\n",
       "       'VINELAND_DOMESTIC_V_SCALED', 'VINELAND_COMMUNITY_V_SCALED',\n",
       "       'VINELAND_DAILYLVNG_STANDARD', 'VINELAND_INTERPERSONAL_V_SCALED',\n",
       "       'VINELAND_PLAY_V_SCALED', 'VINELAND_COPING_V_SCALED',\n",
       "       'VINELAND_SOCIAL_STANDARD', 'VINELAND_SUM_SCORES',\n",
       "       'VINELAND_ABC_STANDARD', 'VINELAND_INFORMANT', 'WISC_IV_VCI',\n",
       "       'WISC_IV_PRI', 'WISC_IV_WMI', 'WISC_IV_PSI', 'WISC_IV_SIM_SCALED',\n",
       "       'WISC_IV_VOCAB_SCALED', 'WISC_IV_INFO_SCALED', 'WISC_IV_BLK_DSN_SCALED',\n",
       "       'WISC_IV_PIC_CON_SCALED', 'WISC_IV_MATRIX_SCALED',\n",
       "       'WISC_IV_DIGIT_SPAN_SCALED', 'WISC_IV_LET_NUM_SCALED',\n",
       "       'WISC_IV_CODING_SCALED', 'WISC_IV_SYM_SCALED', 'EYE_STATUS_AT_SCAN',\n",
       "       'AGE_AT_MPRAGE', 'BMI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42274dc1-4f7c-4420-a2f4-8c2c01e82fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_dat_file = glob.glob(\"/blue/ruogu.fang/ryoi360/projects/fmri_vlm/data/ABIDE_parcelled/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564b1050-413c-49cc-8fd9-1b7b51224c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj_to_fmri_arr = {os.path.basename(path).replace(\"_MNI_2mm.dat\", \"\"): load_dat_file(path) for path in all_dat_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "896faef5-59b1-4627-abd0-9c4cc9e70ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abide_df[\"fmri_arr\"] = abide_df[\"FILE_ID\"].map(subj_to_fmri_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f935d4ad-260e-4f01-b20e-d1381919f4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.18433658,  -6.07196965,  -6.97500883, ...,  -3.41201421,\n",
       "          0.9953801 ,  -1.72951851],\n",
       "       [  0.73146197,  -4.38761729,  -6.44765689, ..., -32.41978836,\n",
       "          2.26119128,   7.04113906],\n",
       "       [ -2.6803328 ,  -2.08896616,  -7.50461406, ..., -50.72791344,\n",
       "          5.01940766,   9.23309426],\n",
       "       ...,\n",
       "       [  5.51452779,   3.73930147, -10.3789194 , ...,   6.16789148,\n",
       "         14.71152254,   1.60544165],\n",
       "       [  1.57698048,  -1.8572631 , -18.06669439, ...,  -1.40416673,\n",
       "         18.47535985, -13.83961682],\n",
       "       [ -0.23791221,  -4.84153936, -13.79866159, ...,  -5.58723652,\n",
       "         16.31697614, -12.75332682]], shape=(146, 166))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abide_df[\"fmri_arr\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1075810-51c7-4825-aa39-d18bd33132c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abide_df = abide_df.dropna(subset=[\"fmri_arr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "771a0268-8090-4211-ac2a-3e58c51db5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/scratch/local/59862614/ipykernel_1979303/2092188008.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abide_df[\"corr_matrix\"] = abide_df[\"fmri_arr\"].apply(lambda x: compute_fisher_z(x))\n"
     ]
    }
   ],
   "source": [
    "abide_df[\"corr_matrix\"] = abide_df[\"fmri_arr\"].apply(lambda x: compute_fisher_z(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc531239-890e-4dd6-ac17-3e37a9207bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.55691396,  1.02633563,  0.62918206, ..., -0.04302107,\n",
       "        -0.18306976, -0.14144837],\n",
       "       [ 1.02633563,  9.55691396,  0.45323908, ..., -0.10637844,\n",
       "        -0.06027886, -0.09394716],\n",
       "       [ 0.62918206,  0.45323908,  9.55691396, ..., -0.14061898,\n",
       "        -0.3746295 , -0.13466304],\n",
       "       ...,\n",
       "       [-0.04302107, -0.10637844, -0.14061898, ...,  9.55691396,\n",
       "         0.31651522,  0.32601488],\n",
       "       [-0.18306976, -0.06027886, -0.3746295 , ...,  0.31651522,\n",
       "         9.55691396,  1.09054817],\n",
       "       [-0.14144837, -0.09394716, -0.13466304, ...,  0.32601488,\n",
       "         1.09054817,  9.55691396]], shape=(166, 166))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abide_df[\"corr_matrix\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c13bc8-0373-4f7b-bcaf-b52b2616e0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"SUB_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521d34b7-fda8-4db2-b428-d1ad5fd635c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CALTECH', 'CMU', 'KKI', 'LEUVEN_1', 'LEUVEN_2', 'MAX_MUN', 'NYU',\n",
       "       'OHSU', 'OLIN', 'PITT', 'SBL', 'SDSU', 'STANFORD', 'TRINITY',\n",
       "       'UCLA_1', 'UCLA_2', 'UM_1', 'UM_2', 'USM', 'YALE'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"SITE_ID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42e96cf-4df9-4fdf-a99e-c5d867b5f333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DX_GROUP\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbcfdab0-a239-40bd-8c8e-09d7532ba1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SITE_ID', 'SUB_ID', 'FILE_ID', 'DX_GROUP', 'DSM_IV_TR', 'AGE_AT_SCAN',\n",
       "       'SEX', 'HANDEDNESS_CATEGORY', 'HANDEDNESS_SCORES', 'FIQ', 'VIQ', 'PIQ',\n",
       "       'FIQ_TEST_TYPE', 'VIQ_TEST_TYPE', 'PIQ_TEST_TYPE',\n",
       "       'ADI_R_SOCIAL_TOTAL_A', 'ADI_R_VERBAL_TOTAL_BV', 'ADI_RRB_TOTAL_C',\n",
       "       'ADI_R_ONSET_TOTAL_D', 'ADI_R_RSRCH_RELIABLE', 'ADOS_MODULE',\n",
       "       'ADOS_TOTAL', 'ADOS_COMM', 'ADOS_SOCIAL', 'ADOS_STEREO_BEHAV',\n",
       "       'ADOS_RSRCH_RELIABLE', 'ADOS_GOTHAM_SOCAFFECT', 'ADOS_GOTHAM_RRB',\n",
       "       'ADOS_GOTHAM_TOTAL', 'ADOS_GOTHAM_SEVERITY', 'SRS_VERSION',\n",
       "       'SRS_RAW_TOTAL', 'SRS_AWARENESS', 'SRS_COGNITION', 'SRS_COMMUNICATION',\n",
       "       'SRS_MOTIVATION', 'SRS_MANNERISMS', 'SCQ_TOTAL', 'AQ_TOTAL',\n",
       "       'COMORBIDITY', 'CURRENT_MED_STATUS', 'MEDICATION_NAME',\n",
       "       'OFF_STIMULANTS_AT_SCAN', 'VINELAND_RECEPTIVE_V_SCALED',\n",
       "       'VINELAND_EXPRESSIVE_V_SCALED', 'VINELAND_WRITTEN_V_SCALED',\n",
       "       'VINELAND_COMMUNICATION_STANDARD', 'VINELAND_PERSONAL_V_SCALED',\n",
       "       'VINELAND_DOMESTIC_V_SCALED', 'VINELAND_COMMUNITY_V_SCALED',\n",
       "       'VINELAND_DAILYLVNG_STANDARD', 'VINELAND_INTERPERSONAL_V_SCALED',\n",
       "       'VINELAND_PLAY_V_SCALED', 'VINELAND_COPING_V_SCALED',\n",
       "       'VINELAND_SOCIAL_STANDARD', 'VINELAND_SUM_SCORES',\n",
       "       'VINELAND_ABC_STANDARD', 'VINELAND_INFORMANT', 'WISC_IV_VCI',\n",
       "       'WISC_IV_PRI', 'WISC_IV_WMI', 'WISC_IV_PSI', 'WISC_IV_SIM_SCALED',\n",
       "       'WISC_IV_VOCAB_SCALED', 'WISC_IV_INFO_SCALED', 'WISC_IV_BLK_DSN_SCALED',\n",
       "       'WISC_IV_PIC_CON_SCALED', 'WISC_IV_MATRIX_SCALED',\n",
       "       'WISC_IV_DIGIT_SPAN_SCALED', 'WISC_IV_LET_NUM_SCALED',\n",
       "       'WISC_IV_CODING_SCALED', 'WISC_IV_SYM_SCALED', 'EYE_STATUS_AT_SCAN',\n",
       "       'AGE_AT_MPRAGE', 'BMI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35837f6-a163-448a-859b-e3090da79e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_metadata_df = pd.read_csv(\"/blue/ruogu.fang/ryoi360/projects/fmri_vlm/results/2025_02_25_ABIDE_processing/Phenotypic_V1_0b_preprocessed1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f0b8635-ae09-47e9-93f6-3e4ec655cd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0.1\n",
      "Unnamed: 0\n",
      "SUB_ID\n",
      "X\n",
      "subject\n",
      "SITE_ID\n",
      "FILE_ID\n",
      "DX_GROUP\n",
      "DSM_IV_TR\n",
      "AGE_AT_SCAN\n",
      "SEX\n",
      "HANDEDNESS_CATEGORY\n",
      "HANDEDNESS_SCORES\n",
      "FIQ\n",
      "VIQ\n",
      "PIQ\n",
      "FIQ_TEST_TYPE\n",
      "VIQ_TEST_TYPE\n",
      "PIQ_TEST_TYPE\n",
      "ADI_R_SOCIAL_TOTAL_A\n",
      "ADI_R_VERBAL_TOTAL_BV\n",
      "ADI_RRB_TOTAL_C\n",
      "ADI_R_ONSET_TOTAL_D\n",
      "ADI_R_RSRCH_RELIABLE\n",
      "ADOS_MODULE\n",
      "ADOS_TOTAL\n",
      "ADOS_COMM\n",
      "ADOS_SOCIAL\n",
      "ADOS_STEREO_BEHAV\n",
      "ADOS_RSRCH_RELIABLE\n",
      "ADOS_GOTHAM_SOCAFFECT\n",
      "ADOS_GOTHAM_RRB\n",
      "ADOS_GOTHAM_TOTAL\n",
      "ADOS_GOTHAM_SEVERITY\n",
      "SRS_VERSION\n",
      "SRS_RAW_TOTAL\n",
      "SRS_AWARENESS\n",
      "SRS_COGNITION\n",
      "SRS_COMMUNICATION\n",
      "SRS_MOTIVATION\n",
      "SRS_MANNERISMS\n",
      "SCQ_TOTAL\n",
      "AQ_TOTAL\n",
      "COMORBIDITY\n",
      "CURRENT_MED_STATUS\n",
      "MEDICATION_NAME\n",
      "OFF_STIMULANTS_AT_SCAN\n",
      "VINELAND_RECEPTIVE_V_SCALED\n",
      "VINELAND_EXPRESSIVE_V_SCALED\n",
      "VINELAND_WRITTEN_V_SCALED\n",
      "VINELAND_COMMUNICATION_STANDARD\n",
      "VINELAND_PERSONAL_V_SCALED\n",
      "VINELAND_DOMESTIC_V_SCALED\n",
      "VINELAND_COMMUNITY_V_SCALED\n",
      "VINELAND_DAILYLVNG_STANDARD\n",
      "VINELAND_INTERPERSONAL_V_SCALED\n",
      "VINELAND_PLAY_V_SCALED\n",
      "VINELAND_COPING_V_SCALED\n",
      "VINELAND_SOCIAL_STANDARD\n",
      "VINELAND_SUM_SCORES\n",
      "VINELAND_ABC_STANDARD\n",
      "VINELAND_INFORMANT\n",
      "WISC_IV_VCI\n",
      "WISC_IV_PRI\n",
      "WISC_IV_WMI\n",
      "WISC_IV_PSI\n",
      "WISC_IV_SIM_SCALED\n",
      "WISC_IV_VOCAB_SCALED\n",
      "WISC_IV_INFO_SCALED\n",
      "WISC_IV_BLK_DSN_SCALED\n",
      "WISC_IV_PIC_CON_SCALED\n",
      "WISC_IV_MATRIX_SCALED\n",
      "WISC_IV_DIGIT_SPAN_SCALED\n",
      "WISC_IV_LET_NUM_SCALED\n",
      "WISC_IV_CODING_SCALED\n",
      "WISC_IV_SYM_SCALED\n",
      "EYE_STATUS_AT_SCAN\n",
      "AGE_AT_MPRAGE\n",
      "BMI\n",
      "anat_cnr\n",
      "anat_efc\n",
      "anat_fber\n",
      "anat_fwhm\n",
      "anat_qi1\n",
      "anat_snr\n",
      "func_efc\n",
      "func_fber\n",
      "func_fwhm\n",
      "func_dvars\n",
      "func_outlier\n",
      "func_quality\n",
      "func_mean_fd\n",
      "func_num_fd\n",
      "func_perc_fd\n",
      "func_gsr\n",
      "qc_rater_1\n",
      "qc_notes_rater_1\n",
      "qc_anat_rater_2\n",
      "qc_anat_notes_rater_2\n",
      "qc_func_rater_2\n",
      "qc_func_notes_rater_2\n",
      "qc_anat_rater_3\n",
      "qc_anat_notes_rater_3\n",
      "qc_func_rater_3\n",
      "qc_func_notes_rater_3\n",
      "SUB_IN_SMP\n"
     ]
    }
   ],
   "source": [
    "for col in preprocessed_metadata_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e05132c9-ef3c-4999-942a-fe05f7a9e5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects after stricter filtering: 714\n"
     ]
    }
   ],
   "source": [
    "motion_filtered_df = preprocessed_metadata_df[(preprocessed_metadata_df['func_mean_fd'] <= 0.2) & (preprocessed_metadata_df['func_num_fd'] < 20)]\n",
    "\n",
    "print(f\"Subjects after stricter filtering: {len(motion_filtered_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "290e81cb-20b4-4edc-9f8c-10a9f8ca6721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_metadata_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ebd4d70-7982-47f6-9b04-5da9f56575fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.116828\n",
       "1       0.322092\n",
       "2       0.127745\n",
       "3       0.128136\n",
       "4       0.070143\n",
       "          ...   \n",
       "1107    0.116186\n",
       "1108    0.140171\n",
       "1109    0.154887\n",
       "1110    0.048246\n",
       "1111    0.168913\n",
       "Name: func_mean_fd, Length: 1112, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_metadata_df[\"func_mean_fd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d39ebbd9-293f-47e7-9167-4678fe35aa7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.7534808758)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_metadata_df[\"func_fwhm\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20545cfc-fb47-4a33-a801-fe4664dd3d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5667c5b9-d64f-4c91-b38b-6b0840dde23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abide_files = glob.glob(\"/orange/ruogu.fang/ryoi360/ABIDE/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de8274fc-96af-414d-862c-2d610b4050db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abide_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7892f4-7dee-4a8a-b994-3791df45cb1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20049441-258c-4119-8e43-9a12f042236f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fmri_img = nib.load(abide_files[0])\n",
    "fmri_data = fmri_img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3182e2-e867-47fa-866a-709987278cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 73, 61, 116)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940701ed-44a5-40b4-b02e-22ee8ac70953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Voxel Size (mm): [3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Get the voxel size from the affine transformation matrix\n",
    "voxel_size = np.sqrt(np.sum(fmri_img.affine[:3, :3] ** 2, axis=0))\n",
    "print(\"Original Voxel Size (mm):\", voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b288a84-e956-413e-889d-f16ed92027fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Install Required Packages\n",
    "If you haven't installed Nipype, Nibabel, and NiLearn, do so using:\n",
    "\n",
    "bash\n",
    "Copy\n",
    "Edit\n",
    "pip install nipype nibabel nilearn numpy scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58581f4-646d-4b58-a50b-6a004fa5679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Preprocessing Steps in Python\n",
    "Step 1: Rigid Body Motion Correction\n",
    "Use SPM's Realign function via Nipype.\n",
    "Alternatively, use FSL's MCFLIRT.\n",
    "SPM12 (via Nipype)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.spm import Realign\n",
    "\n",
    "realign = Realign()\n",
    "realign.inputs.in_files = 'subject_func.nii'  # Replace with your file path\n",
    "realign.inputs.register_to_mean = True\n",
    "realign.run()\n",
    "FSL Alternative\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.fsl import MCFLIRT\n",
    "\n",
    "mcflirt = MCFLIRT()\n",
    "mcflirt.inputs.in_file = 'subject_func.nii'\n",
    "mcflirt.inputs.out_file = 'motion_corrected.nii'\n",
    "mcflirt.run()\n",
    "Step 2: Slice Timing Correction\n",
    "Adjusts for differences in slice acquisition time.\n",
    "Requires TR (repetition time) and slice order.\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.spm import SliceTiming\n",
    "\n",
    "slice_timing = SliceTiming()\n",
    "slice_timing.inputs.in_files = 'motion_corrected.nii'\n",
    "slice_timing.inputs.time_repetition = 2.0  # Set the correct TR\n",
    "slice_timing.run()\n",
    "Step 3: Normalization to MNI Space\n",
    "Warp the functional data into MNI152 template.\n",
    "Use SPM's Normalize or FSL's FLIRT/FNIRT.\n",
    "SPM Normalization\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.spm import Normalize12\n",
    "\n",
    "normalize = Normalize12()\n",
    "normalize.inputs.image_to_align = 'slice_time_corrected.nii'\n",
    "normalize.inputs.apply_to_files = ['slice_time_corrected.nii']\n",
    "normalize.inputs.jobtype = 'estwrite'  # Estimate and apply transformation\n",
    "normalize.run()\n",
    "FSL FLIRT Alternative\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.fsl import FLIRT\n",
    "\n",
    "flirt = FLIRT()\n",
    "flirt.inputs.in_file = 'slice_time_corrected.nii'\n",
    "flirt.inputs.reference = '/usr/local/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz'\n",
    "flirt.inputs.out_file = 'normalized.nii'\n",
    "flirt.run()\n",
    "Step 4: Resampling to 3×3×3 mm³\n",
    "Use NiLearn for resampling.\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nilearn.image import resample_img\n",
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(\"normalized.nii\")\n",
    "\n",
    "resampled_img = resample_img(img, target_affine=np.diag([3, 3, 3, 1]))\n",
    "nib.save(resampled_img, \"resampled_3mm.nii\")\n",
    "Step 5: Spatial Smoothing (FWHM = 6 mm)\n",
    "Apply Gaussian smoothing using NiLearn.\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nilearn.image import smooth_img\n",
    "\n",
    "smoothed_img = smooth_img(\"resampled_3mm.nii\", fwhm=6)\n",
    "smoothed_img.to_filename(\"smoothed.nii\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14084270-635f-420d-bc8e-092d69ec081e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607fa7e-49be-4e90-8af1-662dcc87ef38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda79c1-0261-40ec-a0de-e14f8945a2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68818b9c-bbed-41bc-9bf2-b310731897be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilabel_env",
   "language": "python",
   "name": "nibabel_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
