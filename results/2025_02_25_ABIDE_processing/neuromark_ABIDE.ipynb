{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88126d0-e0bd-47b6-afa8-74046447566d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86cb1e0c-47bf-4c6f-bc1c-4656b2c157f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Example Python script illustrating the multi-step ICA pipeline described in your excerpt.\n",
    "\n",
    "Required libraries:\n",
    "    numpy, scipy, scikit-learn, nibabel (for loading NIfTI, if needed), etc.\n",
    "    \n",
    "DISCLAIMER:\n",
    "    - This is a simplified illustration only. Adjust as needed for your environment.\n",
    "    - Actual Infomax ICA and true ICASSO procedures may differ in details from FastICA.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from scipy.stats import skew\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 1: Load and prepare data\n",
    "# ---------------------------------------------------------------------------\n",
    "def load_fmri_data(list_of_nifti_paths):\n",
    "    \"\"\"\n",
    "    Example loader that:\n",
    "      - Reads each preprocessed 4D fMRI file (time x x_dim x y_dim x z_dim).\n",
    "      - Reshapes to a 2D array: (time, n_voxels).\n",
    "      - Returns a list of subject data arrays.\n",
    "    \"\"\"\n",
    "    subject_data = []\n",
    "    for fpath in list_of_nifti_paths:\n",
    "        img = nib.load(fpath)\n",
    "        data_4d = img.get_fdata()  # shape: (x_dim, y_dim, z_dim, time)\n",
    "        # Move time to axis=0 and flatten the spatial dims:\n",
    "        data_2d = np.reshape(np.moveaxis(data_4d, -1, 0),\n",
    "                             (data_4d.shape[-1], -1))\n",
    "        subject_data.append(data_2d)\n",
    "    return subject_data\n",
    "\n",
    "\n",
    "def individual_subject_pca(subject_data, n_components=110):\n",
    "    \"\"\"\n",
    "    Perform PCA on each subject’s data (time x voxel) to reduce to `n_components`.\n",
    "    Return a list of reduced 2D arrays: (time, n_components).\n",
    "    \"\"\"\n",
    "    subject_pcs = []\n",
    "    for data_2d in subject_data:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        reduced = pca.fit_transform(data_2d)  # shape: (time_points, n_components)\n",
    "        subject_pcs.append(reduced)\n",
    "    return subject_pcs\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 2 & 3: Concatenate individual PCs and run group-level PCA, then ICA\n",
    "# ---------------------------------------------------------------------------\n",
    "def run_group_pca_then_ica(subject_pcs, n_group_components=100,\n",
    "                           n_ica_runs=100, random_state=0):\n",
    "    \"\"\"\n",
    "    - Concatenate each subject's PCA results along the row dimension (time),\n",
    "      forming a large group matrix: (sum_of_times, 110).\n",
    "    - Run a second PCA to reduce to `n_group_components` (default=100).\n",
    "    - Then run multiple ICA (FastICA) attempts for ICASSO-like approach.\n",
    "    - Pick best run based on similarity to a \"consensus\" or by max neg-entropy, etc.\n",
    "    - Return the best-run's IC mixing matrix and the final group-level ICs.\n",
    "    \"\"\"\n",
    "    # 1) Concatenate:\n",
    "    # subject_pcs is a list of arrays shape (time, 110)\n",
    "    group_data = np.concatenate(subject_pcs, axis=0)  # (sum_of_times, 110)\n",
    "    \n",
    "    # 2) PCA to reduce to 100 group-level PCs\n",
    "    group_pca = PCA(n_components=n_group_components, random_state=random_state)\n",
    "    group_pcs_data = group_pca.fit_transform(group_data)  # shape: (sum_of_times, 100)\n",
    "    \n",
    "    # For an \"ICASSO-like\" approach, run multiple ICA with different random seeds:\n",
    "    ica_components_list = []\n",
    "    \n",
    "    # Typically, you might store all unmixing matrices & then do a clustering step.\n",
    "    # Here we do a simplified approach, then pick the \"best\" by average kurtosis, e.g.\n",
    "    for run_idx in range(n_ica_runs):\n",
    "        rng = np.random.RandomState(run_idx)  # or vary seeds\n",
    "        ica_model = FastICA(n_components=n_group_components,\n",
    "                            random_state=rng,\n",
    "                            max_iter=1000)\n",
    "        S_ = ica_model.fit_transform(group_pcs_data)  # shape: (time_points, 100)\n",
    "        # The columns of `S_` are the estimated IC time-courses (component signals).\n",
    "        # The mixing matrix W^-1 is ica_model.mixing_. \n",
    "        # The actual spatial maps can be derived from S_ or from the pseudo-inverse as needed.\n",
    "        # We'll store the \"spatial\" IC patterns as S_.T or do a pinv if you prefer that orientation.\n",
    "        ica_components_list.append(S_.T)\n",
    "    \n",
    "    # Decide which run is \"best\" – e.g., pick run with highest average neg-entropy or kurtosis:\n",
    "    # (Below is a crude example using the sum of absolute kurtosis across all components.)\n",
    "    best_run_idx = None\n",
    "    best_run_metric = -np.inf\n",
    "    for i, comps_2d in enumerate(ica_components_list):\n",
    "        # `comps_2d` shape: (n_components, time_points)\n",
    "        # we could use kurtosis, or negentropy approximation, etc.\n",
    "        # for simplicity, we do:\n",
    "        kurt_vals = np.array([skew(c, bias=False) for c in comps_2d])\n",
    "        # sum of absolute skew:\n",
    "        metric = np.sum(np.abs(kurt_vals))\n",
    "        if metric > best_run_metric:\n",
    "            best_run_metric = metric\n",
    "            best_run_idx = i\n",
    "    \n",
    "    best_ica_maps = ica_components_list[best_run_idx]  # shape: (100, time_points)\n",
    "    \n",
    "    # Reshape or invert to get group-level \"spatial\" components. \n",
    "    # For Infomax-like ICA on PCA outputs, we typically interpret components \n",
    "    # by (pseudo-inverse of mixing) or the dot product with group PCA loadings.\n",
    "    # This example just returns best_ica_maps as \"group-level ICs\" to be refined if needed.\n",
    "    return best_ica_maps  # shape: (n_components, time_points)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 4: Flip IC if its skewness is negative\n",
    "# ---------------------------------------------------------------------------\n",
    "def flip_negative_skew(ics_2d):\n",
    "    \"\"\"\n",
    "    Given 2D array of shape (n_components, n_timepoints/voxels),\n",
    "    compute skewness for each row, flip if negative.\n",
    "    Returns the array with flips applied.\n",
    "    \"\"\"\n",
    "    flipped_ics = ics_2d.copy()\n",
    "    n_comp = flipped_ics.shape[0]\n",
    "    for i in range(n_comp):\n",
    "        # compute skewness for the ith row\n",
    "        val = skew(flipped_ics[i, :], bias=False)\n",
    "        if val < 0:\n",
    "            flipped_ics[i, :] *= -1\n",
    "    return flipped_ics\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Step 5: Greedy matching of two sets of IC maps\n",
    "# ---------------------------------------------------------------------------\n",
    "def greedy_spatial_match(ics_a, ics_b, corr_threshold=0.4):\n",
    "    \"\"\"\n",
    "    ics_a, ics_b: each shape = (n_components, n_voxels) or (n_components, n_timepoints)\n",
    "                  but typically you'd have them in \"spatial map\" form (component x voxel).\n",
    "    \n",
    "    1. Compute an abs-correlation matrix between the two sets of ics, shape= (Na, Nb).\n",
    "    2. Repeatedly pick the max correlation pair, sign-flip if original correlation is negative.\n",
    "    3. Zero out that row and column to exclude them from further pairing.\n",
    "    4. Return the matched pairs that exceed the threshold, plus their sign-flipped versions.\n",
    "    \"\"\"\n",
    "    nA, nV = ics_a.shape\n",
    "    nB, _ = ics_b.shape\n",
    "    # correlation matrix (absolute value)\n",
    "    # We'll keep track of the sign as well. \n",
    "    corr_mat = np.zeros((nA, nB))\n",
    "    sign_mat = np.zeros((nA, nB))\n",
    "    \n",
    "    for i in range(nA):\n",
    "        for j in range(nB):\n",
    "            corr_ij = np.corrcoef(ics_a[i,:], ics_b[j,:])[0,1]\n",
    "            corr_mat[i,j] = abs(corr_ij)\n",
    "            sign_mat[i,j] = np.sign(corr_ij)  # +1 or -1 or 0\n",
    "    \n",
    "    # Now do the iterative \"greedy\" selection:\n",
    "    matched_pairs = []  # will store tuples like (idxA, idxB, correlation, sign_of_correlation)\n",
    "    \n",
    "    # Make a copy of corr_mat to zero out as we pick pairs\n",
    "    tmp_corr = corr_mat.copy()\n",
    "    \n",
    "    for _ in range(nA):  # up to min(nA,nB) matches\n",
    "        # find max in tmp_corr\n",
    "        i_max, j_max = np.unravel_index(np.argmax(tmp_corr), tmp_corr.shape)\n",
    "        max_val = tmp_corr[i_max, j_max]\n",
    "        if max_val < corr_threshold:\n",
    "            # no more pairs exceed threshold\n",
    "            break\n",
    "        \n",
    "        matched_pairs.append((i_max, j_max, max_val, sign_mat[i_max,j_max]))\n",
    "        \n",
    "        # zero out that row and column\n",
    "        tmp_corr[i_max, :] = 0.0\n",
    "        tmp_corr[:, j_max] = 0.0\n",
    "    \n",
    "    # If correlation sign was negative, we sign-flip ICS_B’s component \n",
    "    # or ICS_A’s, but typically flip ICS_B for convenience. \n",
    "    # (In actual pipeline, you might want to store a separate copy for the flips.)\n",
    "    # We'll do it in-place here for demonstration.\n",
    "    for (ia, ib, val, sgn) in matched_pairs:\n",
    "        if sgn < 0:\n",
    "            ics_b[ib,:] *= -1\n",
    "    \n",
    "    # Return the subset of matched pairs that exceed threshold \n",
    "    # plus the possibly sign-flipped ics_b:\n",
    "    final_pairs = [p for p in matched_pairs if p[2] >= corr_threshold]\n",
    "    return final_pairs, ics_a, ics_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4455099b-cc98-4b8e-8369-45d1e0183682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Main demonstration function\n",
    "# ---------------------------------------------------------------------------\n",
    "def main_example():\n",
    "    \"\"\"\n",
    "    Demonstrate the pipeline, step by step, using hypothetical file lists\n",
    "    for two cohorts: controls and disease.\n",
    "    \"\"\"\n",
    "    # Hypothetical example: lists of NIfTI paths\n",
    "    #  - Replace with your actual preprocessed fMRI NIfTI files\n",
    "    control_paths = [\"/path/to/control_subject_01_preproc.nii.gz\",\n",
    "                     \"/path/to/control_subject_02_preproc.nii.gz\",\n",
    "                     # ...\n",
    "                    ]\n",
    "    disease_paths = [\"/path/to/disease_subject_01_preproc.nii.gz\",\n",
    "                     \"/path/to/disease_subject_02_preproc.nii.gz\",\n",
    "                     # ...\n",
    "                    ]\n",
    "    \n",
    "    # 1) Load data & do subject-level PCA\n",
    "    control_data = load_fmri_data(control_paths)   # list of arrays (time x voxel)\n",
    "    disease_data = load_fmri_data(disease_paths)   # list of arrays (time x voxel)\n",
    "    \n",
    "    control_pcs = individual_subject_pca(control_data, n_components=110)\n",
    "    disease_pcs = individual_subject_pca(disease_data, n_components=110)\n",
    "    \n",
    "    # 2 & 3) Group-level PCA then ICA with repeated runs (ICASSO style)\n",
    "    ctrl_group_ics = run_group_pca_then_ica(control_pcs,\n",
    "                                            n_group_components=100,\n",
    "                                            n_ica_runs=100,\n",
    "                                            random_state=0)\n",
    "    dis_group_ics  = run_group_pca_then_ica(disease_pcs,\n",
    "                                            n_group_components=100,\n",
    "                                            n_ica_runs=100,\n",
    "                                            random_state=0)\n",
    "    # ctrl_group_ics, dis_group_ics each shape: (100, group_time_points)\n",
    "    # but for matching we usually want them as (100, voxel), i.e. \"spatial maps.\"\n",
    "    # If your group-time dimension is not the same as voxel dimension, you'd \n",
    "    # typically invert the mixing or do post-processing to obtain spatial maps.\n",
    "    # We'll pretend these are already \"spatial\" for the sake of demonstration.\n",
    "    \n",
    "    # 4) Flip negative skewness\n",
    "    ctrl_group_ics = flip_negative_skew(ctrl_group_ics)\n",
    "    dis_group_ics  = flip_negative_skew(dis_group_ics)\n",
    "    \n",
    "    # 5) Greedy matching between the two sets\n",
    "    matched_pairs, ctrl_flipped, dis_flipped = greedy_spatial_match(\n",
    "        ctrl_group_ics,\n",
    "        dis_group_ics,\n",
    "        corr_threshold=0.4\n",
    "    )\n",
    "    \n",
    "    print(f\"Number of matched IC pairs (corr>0.4): {len(matched_pairs)}\")\n",
    "    for pair in matched_pairs:\n",
    "        iA, iB, corr_val, sign_ = pair\n",
    "        print(f\"  Pair: IC_ctrl={iA}, IC_dis={iB}, corr={corr_val:.3f}, sign={sign_}\")\n",
    "    \n",
    "    # The matched_pairs with correlation > 0.4 are considered reproducible ICs. \n",
    "    # Next steps might include:\n",
    "    #   - Inspect each matched IC pair’s spatial pattern.\n",
    "    #   - Exclude artifactual components using heuristics (peak in gray matter, etc.).\n",
    "    #   - Compare final sets of reproducible ICNs across cohorts.\n",
    "    #   - Downstream connectivity/functional analyses.\n",
    "\n",
    "    print(\"Done. This demonstration performed the group-ICA-like pipeline.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a42efa1-9217-4215-92a5-e3d2d72257f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(\"./Phenotypic_V1_0b_preprocessed1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0180a4c6-72ce-4e00-88e3-bd3c1d11f1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_notes_rater_1</th>\n",
       "      <th>qc_anat_rater_2</th>\n",
       "      <th>qc_anat_notes_rater_2</th>\n",
       "      <th>qc_func_rater_2</th>\n",
       "      <th>qc_func_notes_rater_2</th>\n",
       "      <th>qc_anat_rater_3</th>\n",
       "      <th>qc_anat_notes_rater_3</th>\n",
       "      <th>qc_func_rater_3</th>\n",
       "      <th>qc_func_notes_rater_3</th>\n",
       "      <th>SUB_IN_SMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.77</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fail</td>\n",
       "      <td>ic-parietal-cerebellum</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fail</td>\n",
       "      <td>ERROR #24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-parietal-cerebellum</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.37</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-parietal slight</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  \\\n",
       "0             0           1   50002  1    50002    PITT   no_filename   \n",
       "1             1           2   50003  2    50003    PITT  Pitt_0050003   \n",
       "2             2           3   50004  3    50004    PITT  Pitt_0050004   \n",
       "3             3           4   50005  4    50005    PITT  Pitt_0050005   \n",
       "4             4           5   50006  5    50006    PITT  Pitt_0050006   \n",
       "\n",
       "   DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  ...  qc_notes_rater_1 qc_anat_rater_2  \\\n",
       "0         1          1        16.77  ...               NaN              OK   \n",
       "1         1          1        24.45  ...               NaN              OK   \n",
       "2         1          1        19.09  ...               NaN              OK   \n",
       "3         1          1        13.73  ...               NaN              OK   \n",
       "4         1          1        13.37  ...               NaN              OK   \n",
       "\n",
       "   qc_anat_notes_rater_2  qc_func_rater_2   qc_func_notes_rater_2  \\\n",
       "0                    NaN             fail  ic-parietal-cerebellum   \n",
       "1                    NaN               OK                     NaN   \n",
       "2                    NaN               OK                     NaN   \n",
       "3                    NaN            maybe  ic-parietal-cerebellum   \n",
       "4                    NaN            maybe      ic-parietal slight   \n",
       "\n",
       "   qc_anat_rater_3 qc_anat_notes_rater_3 qc_func_rater_3  \\\n",
       "0               OK                   NaN            fail   \n",
       "1               OK                   NaN              OK   \n",
       "2               OK                   NaN              OK   \n",
       "3               OK                   NaN              OK   \n",
       "4               OK                   NaN              OK   \n",
       "\n",
       "  qc_func_notes_rater_3  SUB_IN_SMP  \n",
       "0             ERROR #24           1  \n",
       "1                   NaN           1  \n",
       "2                   NaN           1  \n",
       "3                   NaN           0  \n",
       "4                   NaN           1  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df[metadata_df[\"DX_GROUP\"] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43b12804-1184-41ec-81fd-4291a3ff6391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_notes_rater_1</th>\n",
       "      <th>qc_anat_rater_2</th>\n",
       "      <th>qc_anat_notes_rater_2</th>\n",
       "      <th>qc_func_rater_2</th>\n",
       "      <th>qc_func_notes_rater_2</th>\n",
       "      <th>qc_anat_rater_3</th>\n",
       "      <th>qc_anat_notes_rater_3</th>\n",
       "      <th>qc_func_rater_3</th>\n",
       "      <th>qc_func_notes_rater_3</th>\n",
       "      <th>SUB_IN_SMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>50030</td>\n",
       "      <td>27</td>\n",
       "      <td>50030</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050030</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-parietal-cerebellum</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>50031</td>\n",
       "      <td>28</td>\n",
       "      <td>50031</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050031</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-cerebellum_temporal_lobe</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>50032</td>\n",
       "      <td>29</td>\n",
       "      <td>50032</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050032</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-cerebellum_temporal_lobe</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>50033</td>\n",
       "      <td>30</td>\n",
       "      <td>50033</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050033</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-cerebellum_temporal_lobe</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>50034</td>\n",
       "      <td>31</td>\n",
       "      <td>50034</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050034</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.77</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-cerebellum_temporal_lobe</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  SUB_ID   X  subject SITE_ID       FILE_ID  \\\n",
       "26            26          27   50030  27    50030    PITT  Pitt_0050030   \n",
       "27            27          28   50031  28    50031    PITT  Pitt_0050031   \n",
       "28            28          29   50032  29    50032    PITT  Pitt_0050032   \n",
       "29            29          30   50033  30    50033    PITT  Pitt_0050033   \n",
       "30            30          31   50034  31    50034    PITT  Pitt_0050034   \n",
       "\n",
       "    DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  ...  qc_notes_rater_1 qc_anat_rater_2  \\\n",
       "26         2          0        25.12  ...               NaN              OK   \n",
       "27         2          0        12.92  ...               NaN              OK   \n",
       "28         2          0        19.80  ...               NaN              OK   \n",
       "29         2          0        12.15  ...               NaN              OK   \n",
       "30         2          0        14.77  ...               NaN              OK   \n",
       "\n",
       "    qc_anat_notes_rater_2  qc_func_rater_2        qc_func_notes_rater_2  \\\n",
       "26                    NaN            maybe       ic-parietal-cerebellum   \n",
       "27                    NaN            maybe  ic-cerebellum_temporal_lobe   \n",
       "28                    NaN            maybe  ic-cerebellum_temporal_lobe   \n",
       "29                    NaN            maybe  ic-cerebellum_temporal_lobe   \n",
       "30                    NaN            maybe  ic-cerebellum_temporal_lobe   \n",
       "\n",
       "    qc_anat_rater_3 qc_anat_notes_rater_3 qc_func_rater_3  \\\n",
       "26               OK                   NaN              OK   \n",
       "27               OK                   NaN              OK   \n",
       "28               OK                   NaN              OK   \n",
       "29               OK                   NaN              OK   \n",
       "30               OK                   NaN              OK   \n",
       "\n",
       "   qc_func_notes_rater_3  SUB_IN_SMP  \n",
       "26                   NaN           1  \n",
       "27                   NaN           1  \n",
       "28                   NaN           1  \n",
       "29                   NaN           1  \n",
       "30                   NaN           1  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df[metadata_df[\"DX_GROUP\"] == 2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d85705b-fb33-4baf-bd80-bb3e8db41448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "control_file_IDS = metadata_df[metadata_df[\"DX_GROUP\"] == 2][\"FILE_ID\"].to_list()\n",
    "ASD_file_IDS = metadata_df[metadata_df[\"DX_GROUP\"] == 1][\"FILE_ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28baaf89-799b-4df0-ac36-b25e8e82f8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_fmri_files = glob.glob(\"/blue/ruogu.fang/ryoi360/projects/fmri_vlm/data/ABIDE_MNI_SMOOTH/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06c18cdf-95c2-44b4-9efa-216dd0e4c2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "control_paths = [path for path in all_fmri_files if os.path.basename(path).replace(\"_MNI_smoothed.nii.gz\", \"\") in control_file_IDS]\n",
    "disease_paths = [path for path in all_fmri_files if os.path.basename(path).replace(\"_MNI_smoothed.nii.gz\", \"\") in ASD_file_IDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53ab7ced-a446-44f6-bb2c-3a6247bd99e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'whiten' parameter of FastICA must be a str among {'unit-variance', 'arbitrary-variance'} or a bool among {False}. Got True instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m disease_pcs \u001b[38;5;241m=\u001b[39m individual_subject_pca(disease_data, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m110\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 2 & 3) Group-level PCA then ICA with repeated runs (ICASSO style)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m ctrl_group_ics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_group_pca_then_ica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol_pcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mn_group_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mn_ica_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m dis_group_ics  \u001b[38;5;241m=\u001b[39m run_group_pca_then_ica(disease_pcs,\n\u001b[1;32m     17\u001b[0m                                         n_group_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                         n_ica_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     19\u001b[0m                                         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# ctrl_group_ics, dis_group_ics each shape: (100, group_time_points)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# but for matching we usually want them as (100, voxel), i.e. \"spatial maps.\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# If your group-time dimension is not the same as voxel dimension, you'd \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 4) Flip negative skewness\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 85\u001b[0m, in \u001b[0;36mrun_group_pca_then_ica\u001b[0;34m(subject_pcs, n_group_components, n_ica_runs, random_state)\u001b[0m\n\u001b[1;32m     80\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(run_idx)  \u001b[38;5;66;03m# or vary seeds\u001b[39;00m\n\u001b[1;32m     81\u001b[0m ica_model \u001b[38;5;241m=\u001b[39m FastICA(n_components\u001b[38;5;241m=\u001b[39mn_group_components,\n\u001b[1;32m     82\u001b[0m                     random_state\u001b[38;5;241m=\u001b[39mrng,\n\u001b[1;32m     83\u001b[0m                     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     84\u001b[0m                     whiten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 85\u001b[0m S_ \u001b[38;5;241m=\u001b[39m \u001b[43mica_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_pcs_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (time_points, 100)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# The columns of `S_` are the estimated IC time-courses (component signals).\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# The mixing matrix W^-1 is ica_model.mixing_. \u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# The actual spatial maps can be derived from S_ or from the pseudo-inverse as needed.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# We'll store the \"spatial\" IC patterns as S_.T or do a pinv if you prefer that orientation.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m ica_components_list\u001b[38;5;241m.\u001b[39mappend(S_\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[0;32m/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/sklearn/base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1378\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1382\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/sklearn/base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'whiten' parameter of FastICA must be a str among {'unit-variance', 'arbitrary-variance'} or a bool among {False}. Got True instead."
     ]
    }
   ],
   "source": [
    "# Hypothetical example: lists of NIfTI paths\n",
    "#  - Replace with your actual preprocessed fMRI NIfTI files\n",
    "\n",
    "# 1) Load data & do subject-level PCA\n",
    "control_data = load_fmri_data(control_paths[:25])   # list of arrays (time x voxel)\n",
    "disease_data = load_fmri_data(disease_paths[:25])   # list of arrays (time x voxel)\n",
    "\n",
    "control_pcs = individual_subject_pca(control_data, n_components=110)\n",
    "disease_pcs = individual_subject_pca(disease_data, n_components=110)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d876ddb7-64bc-4530-b5c8-277fa1084232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4452 and the array at index 1 has size 5436",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m dis_group_ics  \u001b[38;5;241m=\u001b[39m flip_negative_skew(dis_group_ics)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 5) Greedy matching between the two sets\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m matched_pairs, ctrl_flipped, dis_flipped \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_spatial_match\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctrl_group_ics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdis_group_ics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorr_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of matched IC pairs (corr>0.4): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(matched_pairs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m matched_pairs:\n",
      "Cell \u001b[0;32mIn[44], line 156\u001b[0m, in \u001b[0;36mgreedy_spatial_match\u001b[0;34m(ics_a, ics_b, corr_threshold)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nA):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nB):\n\u001b[0;32m--> 156\u001b[0m         corr_ij \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mics_a\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mics_b\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    157\u001b[0m         corr_mat[i,j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(corr_ij)\n\u001b[1;32m    158\u001b[0m         sign_mat[i,j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(corr_ij)  \u001b[38;5;66;03m# +1 or -1 or 0\u001b[39;00m\n",
      "File \u001b[0;32m/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3037\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   3034\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   3036\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 3037\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3039\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m/blue/ruogu.fang/ryoi360/projects/fmri_vlm/bin/conda/nibabel_env/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:2829\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rowvar \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2828\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m-> 2829\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4452 and the array at index 1 has size 5436"
     ]
    }
   ],
   "source": [
    "# 2 & 3) Group-level PCA then ICA with repeated runs (ICASSO style)\n",
    "ctrl_group_ics = run_group_pca_then_ica(control_pcs,\n",
    "                                        n_group_components=100,\n",
    "                                        n_ica_runs=100,\n",
    "                                        random_state=0)\n",
    "dis_group_ics  = run_group_pca_then_ica(disease_pcs,\n",
    "                                        n_group_components=100,\n",
    "                                        n_ica_runs=100,\n",
    "                                        random_state=0)\n",
    "# ctrl_group_ics, dis_group_ics each shape: (100, group_time_points)\n",
    "# but for matching we usually want them as (100, voxel), i.e. \"spatial maps.\"\n",
    "# If your group-time dimension is not the same as voxel dimension, you'd \n",
    "# typically invert the mixing or do post-processing to obtain spatial maps.\n",
    "# We'll pretend these are already \"spatial\" for the sake of demonstration.\n",
    "\n",
    "# 4) Flip negative skewness\n",
    "ctrl_group_ics = flip_negative_skew(ctrl_group_ics)\n",
    "dis_group_ics  = flip_negative_skew(dis_group_ics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338da496-0df0-4209-9a51-bc8b75fa6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Greedy matching between the two sets\n",
    "matched_pairs, ctrl_flipped, dis_flipped = greedy_spatial_match(\n",
    "    ctrl_group_ics,\n",
    "    dis_group_ics,\n",
    "    corr_threshold=0.4\n",
    ")\n",
    "\n",
    "print(f\"Number of matched IC pairs (corr>0.4): {len(matched_pairs)}\")\n",
    "for pair in matched_pairs:\n",
    "    iA, iB, corr_val, sign_ = pair\n",
    "    print(f\"  Pair: IC_ctrl={iA}, IC_dis={iB}, corr={corr_val:.3f}, sign={sign_}\")\n",
    "\n",
    "# The matched_pairs with correlation > 0.4 are considered reproducible ICs. \n",
    "# Next steps might include:\n",
    "#   - Inspect each matched IC pair’s spatial pattern.\n",
    "#   - Exclude artifactual components using heuristics (peak in gray matter, etc.).\n",
    "#   - Compare final sets of reproducible ICNs across cohorts.\n",
    "#   - Downstream connectivity/functional analyses.\n",
    "\n",
    "print(\"Done. This demonstration performed the group-ICA-like pipeline.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e09ab4a-8336-4905-9544-ff85c2ecd13e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.49688443e-03, -1.07463879e-01,  2.18822596e-01, ...,\n",
       "         1.43537749e-01, -3.08436589e-01, -7.16405206e-01],\n",
       "       [ 4.51096422e-02,  3.44334725e-02, -1.58252708e-02, ...,\n",
       "         6.88624111e-02,  1.50578049e-01,  1.98669039e-01],\n",
       "       [-4.64069301e-01, -6.10793096e-01, -2.89490354e-01, ...,\n",
       "        -7.00814036e-01,  2.49008887e-01,  7.74731790e-01],\n",
       "       ...,\n",
       "       [-8.77152491e-01, -9.55246325e-01,  1.54314870e-01, ...,\n",
       "         9.43521484e-01, -7.79410708e-02, -8.60677198e-01],\n",
       "       [-1.25323515e-03,  1.69680524e-02,  1.35392343e-02, ...,\n",
       "         3.09528369e+00,  9.81202538e-01, -1.70429622e+00],\n",
       "       [-1.51925821e+00, -1.19345454e+00,  6.97358972e-01, ...,\n",
       "        -1.72784682e+00, -2.35007360e+00, -2.09667513e+00]],\n",
       "      shape=(100, 4452))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl_group_ics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635223c6-a43e-4b38-b99b-df3c26336f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import convolve\n",
    "\n",
    "def adaptive_ica_single_component(Xw, template, alpha=0.5, max_iter=200, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Demonstration of a single-component GIG-ICA-like update.\n",
    "    Xw:   (T, V) the subject's *whitened* data (time x voxel).\n",
    "    template: (V,) the l-th template (already normalized or not).\n",
    "    alpha: weighting (0.5 => half independence, half prior similarity).\n",
    "    max_iter, tol: iteration settings.\n",
    "    \n",
    "    Returns:\n",
    "        w:  (V,) the unmixing vector for this single component\n",
    "        s:  (T,) the subject-specific time course (or can interpret it as the comp. activation).\n",
    "        c:  (V,) the subject-specific spatial map S^l_k\n",
    "    NOTE:\n",
    "      - This is a conceptual gradient-based approach. Real GIG-ICA uses Infomax-like updates.\n",
    "      - We treat 'negentropy' term with a popular approximation via e.g. G(u)=log(cosh(u)).\n",
    "      - The prior-similarity term is a dot product with the template (or correlation).\n",
    "    \"\"\"\n",
    "    T, V = Xw.shape\n",
    "    # Initialize w randomly, then normalize\n",
    "    rng = np.random.RandomState(0)\n",
    "    w = rng.randn(V)\n",
    "    w /= norm(w)\n",
    "\n",
    "    # Precompute a normalized template if desired:\n",
    "    # If we want a pure dot product measure: just do template_norm = template.\n",
    "    # If we prefer correlation-like measure, standardize template:\n",
    "    ttemp = zscore(template)  # zero-mean, unit-std\n",
    "\n",
    "    def negentropy_grad(s, Xw):\n",
    "        \"\"\"\n",
    "        Approx gradient of negentropy wrt w.\n",
    "        We'll use G(u)= log(cosh(u)) as a standard nonlinearity.\n",
    "        s = Xw @ w^T => shape (T,)\n",
    "        \"\"\"\n",
    "        # derivative of logcosh(s) ~ tanh(s)\n",
    "        # gradient wrt w ~ Xw.T * tanh(s)\n",
    "        return Xw.T.dot(np.tanh(s))\n",
    "\n",
    "    def similarity_grad(s, Xw, ttemp):\n",
    "        \"\"\"\n",
    "        Approx gradient of correlation wrt w. \n",
    "        correlation(s, template) ~ (s - mean(s))*(template - mean(template)) / (std(s)*std(template))\n",
    "        For simplicity, we skip some partial derivative complexities and treat it as a dot product\n",
    "        with zscored data to illustrate the idea. \n",
    "        \"\"\"\n",
    "        # s is shape (T,). Let's zscore s => sZ. Then dot(sZ, ttemp) is correlation ~ sZ dot ttemp\n",
    "        sZ = zscore(s)  # zero-mean, unit-std\n",
    "        # derivative wrt w => derivative of sZ wrt s times derivative of s wrt w...\n",
    "        # but let's keep it simpler: approximate\n",
    "        # We'll do a direct dot-product measure: \"similarity ~ s^T * template\"\n",
    "        # Then gradient is Xw.T * template\n",
    "        # for correlation-like measure, we can do Xw.T * ttemp\n",
    "        grad_approx = Xw.T.dot(ttemp)\n",
    "        return grad_approx\n",
    "\n",
    "    # Iterative gradient-based update\n",
    "    last_w = w.copy()\n",
    "    for i in range(max_iter):\n",
    "        # Project: s = Xw @ w\n",
    "        s = Xw.dot(w)\n",
    "        # Weighted gradient = alpha*(negentropy_grad) + (1-alpha)*(similarity_grad)\n",
    "        g1 = negentropy_grad(s, Xw)\n",
    "        g2 = similarity_grad(s, Xw, ttemp)\n",
    "        grad = alpha*g1 + (1-alpha)*g2\n",
    "        \n",
    "        # Orthogonalize if you want multiple comps. We'll do single comp for demonstration.\n",
    "        \n",
    "        # Update step: w_new = old + step_size * grad\n",
    "        # step_size can be adapted. We'll pick a small constant. \n",
    "        step_size = 1e-5  \n",
    "        w_new = w + step_size * grad\n",
    "        \n",
    "        # re-normalize\n",
    "        w_new /= norm(w_new)\n",
    "        \n",
    "        # check convergence\n",
    "        if norm(w_new - w) < tol:\n",
    "            w = w_new\n",
    "            break\n",
    "        \n",
    "        w = w_new\n",
    "    \n",
    "    # final projection\n",
    "    s_final = Xw.dot(w)  # shape (T,)\n",
    "    # subject-specific SPATIAL map c = Xw^T * s, or see how you interpret it\n",
    "    # typically if w is the unmixing, then c = w^T * (cov or something)\n",
    "    # We'll do a direct map:\n",
    "    c_final = s_final @ Xw / (T - 1)  # rough approach\n",
    "\n",
    "    # Z-score the spatial map if desired\n",
    "    c_final_z = zscore(c_final)\n",
    "    \n",
    "    return w, s_final, c_final_z\n",
    "\n",
    "\n",
    "def subject_adaptive_ica(X, group_templates, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Illustrate how to get ALL subject-specific networks \n",
    "    given the set of group-level templates.\n",
    "    \n",
    "    X:  (T, V) raw data for one subject (time x voxel).\n",
    "    group_templates: (N, V) for N templates/ICNs.\n",
    "    alpha: weighting for independence vs. prior similarity.\n",
    "    \n",
    "    Steps:\n",
    "      1) Whiten X\n",
    "      2) For each template -> run the single-component optimization\n",
    "      3) Collect subject-specific networks and time-courses\n",
    "    Returns:\n",
    "      sps_maps:   array (N, V)\n",
    "      time_courses: array (N, T)\n",
    "    \"\"\"\n",
    "    T, V = X.shape\n",
    "    # 1) Whiten the data\n",
    "    #   Typically we do PCA => whiten => Xw shape (T, V)\n",
    "    X_mean = X.mean(axis=0)\n",
    "    Xc = X - X_mean\n",
    "    # compute SVD or PCA:\n",
    "    U, S, VT = np.linalg.svd(Xc, full_matrices=False)\n",
    "    # whitened data\n",
    "    # Xc = U @ diag(S) @ VT so let's do Xw = U @ I\n",
    "    # or we can do: Xw = (U * diag(1/S))^T ...\n",
    "    # let's do the simpler: Xw = U * factor\n",
    "    # But note shape: we want Xw => (T, V)\n",
    "    # We'll do Xw = U * sqrt(T-1). But let's keep it simpler:\n",
    "    Xw = U.copy()\n",
    "    \n",
    "    # 2) For each template, do the single-comp solver\n",
    "    N = group_templates.shape[0]\n",
    "    sps_maps = np.zeros((N, V))\n",
    "    time_courses = np.zeros((N, T))\n",
    "    for l in range(N):\n",
    "        template_l = group_templates[l,:]\n",
    "        w_l, s_l, c_l = adaptive_ica_single_component(\n",
    "            Xw, template_l, alpha=alpha, max_iter=200, tol=1e-5\n",
    "        )\n",
    "        # c_l is the subject-specific spatial map\n",
    "        sps_maps[l, :] = c_l\n",
    "        \n",
    "        # Also define time-course as correlation between data and that map,\n",
    "        # or project raw data onto c_l.  We'll do a simple dot:\n",
    "        # time-course = Xc * c_l^T\n",
    "        # but typically you might want to invert the mixing matrix, etc. \n",
    "        # For demonstration:\n",
    "        tc = (Xc.dot(c_l))  # shape (T,)\n",
    "        # optional zscore:\n",
    "        tc_z = zscore(tc)\n",
    "        time_courses[l, :] = tc_z\n",
    "    \n",
    "    return sps_maps, time_courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6c6fa-5ae9-4e75-9cdc-0cbf858daacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr, zscore\n",
    "\n",
    "def compute_static_fnc(time_courses):\n",
    "    \"\"\"\n",
    "    Given time_courses of shape (N, T) for N ICNs, T timepoints,\n",
    "    compute an N x N static functional connectivity matrix \n",
    "    by Pearson correlation between each pair of time-courses.\n",
    "    \"\"\"\n",
    "    N, T = time_courses.shape\n",
    "    fnc_matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            r, _ = pearsonr(time_courses[i,:], time_courses[j,:])\n",
    "            fnc_matrix[i,j] = r\n",
    "    return fnc_matrix\n",
    "\n",
    "def compute_dynamic_fnc(time_courses, window_length=30, step=1):\n",
    "    \"\"\"\n",
    "    Simple demonstration of dynamic FNC with a sliding window.\n",
    "    time_courses: (N, T)\n",
    "    window_length: number of time points per window\n",
    "    step: step size (in timepoints) for sliding\n",
    "    \n",
    "    Returns:\n",
    "      A list of FNC matrices, each (N, N), or we can stack them in array (numWindows, N, N).\n",
    "    \"\"\"\n",
    "    N, T = time_courses.shape\n",
    "    windowed_FNC = []\n",
    "    start = 0\n",
    "    while (start + window_length) <= T:\n",
    "        seg = time_courses[:, start : start+window_length]  # shape (N, window_length)\n",
    "        # correlation\n",
    "        fnc_mat = np.zeros((N, N))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                r, _ = pearsonr(seg[i,:], seg[j,:])\n",
    "                fnc_mat[i,j] = r\n",
    "        windowed_FNC.append(fnc_mat)\n",
    "        start += step\n",
    "    \n",
    "    # Optionally, convert to a 3D array: (numWindows x N x N)\n",
    "    windowed_FNC = np.array(windowed_FNC)\n",
    "    return windowed_FNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c8e01-2c15-410f-8153-2b0e5fc54557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we already obtained for one subject:\n",
    "#   sps_maps (N, V) and time_courses (N, T).\n",
    "# Example: compute sFNC\n",
    "sFNC = compute_static_fnc(time_courses)  # shape (N, N)\n",
    "\n",
    "# Example: compute dFNC using a 30-TR window sliding by 1\n",
    "dFNC_array = compute_dynamic_fnc(time_courses, window_length=30, step=1)\n",
    "# shape: (num_windows, N, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e54ba24e-c4b4-4af4-b786-d453f5f324b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc54b6-87a0-490f-8b54-0f81eb1b5ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596ef43-c633-42c5-941e-b2d03b03eecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c9ee3-52e7-4360-8927-5490813013de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3cf39-10ee-4ae7-a8fa-76bc4d89dc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cb5d515-4649-4d23-9e05-d6e11d30d978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1466.948974609375)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9db67d2-d808-4a3e-bb77-c3d5c0e4663e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 259200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c13bc8-0373-4f7b-bcaf-b52b2616e0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"SUB_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521d34b7-fda8-4db2-b428-d1ad5fd635c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CALTECH', 'CMU', 'KKI', 'LEUVEN_1', 'LEUVEN_2', 'MAX_MUN', 'NYU',\n",
       "       'OHSU', 'OLIN', 'PITT', 'SBL', 'SDSU', 'STANFORD', 'TRINITY',\n",
       "       'UCLA_1', 'UCLA_2', 'UM_1', 'UM_2', 'USM', 'YALE'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"SITE_ID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42e96cf-4df9-4fdf-a99e-c5d867b5f333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DX_GROUP\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbcfdab0-a239-40bd-8c8e-09d7532ba1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SITE_ID', 'SUB_ID', 'FILE_ID', 'DX_GROUP', 'DSM_IV_TR', 'AGE_AT_SCAN',\n",
       "       'SEX', 'HANDEDNESS_CATEGORY', 'HANDEDNESS_SCORES', 'FIQ', 'VIQ', 'PIQ',\n",
       "       'FIQ_TEST_TYPE', 'VIQ_TEST_TYPE', 'PIQ_TEST_TYPE',\n",
       "       'ADI_R_SOCIAL_TOTAL_A', 'ADI_R_VERBAL_TOTAL_BV', 'ADI_RRB_TOTAL_C',\n",
       "       'ADI_R_ONSET_TOTAL_D', 'ADI_R_RSRCH_RELIABLE', 'ADOS_MODULE',\n",
       "       'ADOS_TOTAL', 'ADOS_COMM', 'ADOS_SOCIAL', 'ADOS_STEREO_BEHAV',\n",
       "       'ADOS_RSRCH_RELIABLE', 'ADOS_GOTHAM_SOCAFFECT', 'ADOS_GOTHAM_RRB',\n",
       "       'ADOS_GOTHAM_TOTAL', 'ADOS_GOTHAM_SEVERITY', 'SRS_VERSION',\n",
       "       'SRS_RAW_TOTAL', 'SRS_AWARENESS', 'SRS_COGNITION', 'SRS_COMMUNICATION',\n",
       "       'SRS_MOTIVATION', 'SRS_MANNERISMS', 'SCQ_TOTAL', 'AQ_TOTAL',\n",
       "       'COMORBIDITY', 'CURRENT_MED_STATUS', 'MEDICATION_NAME',\n",
       "       'OFF_STIMULANTS_AT_SCAN', 'VINELAND_RECEPTIVE_V_SCALED',\n",
       "       'VINELAND_EXPRESSIVE_V_SCALED', 'VINELAND_WRITTEN_V_SCALED',\n",
       "       'VINELAND_COMMUNICATION_STANDARD', 'VINELAND_PERSONAL_V_SCALED',\n",
       "       'VINELAND_DOMESTIC_V_SCALED', 'VINELAND_COMMUNITY_V_SCALED',\n",
       "       'VINELAND_DAILYLVNG_STANDARD', 'VINELAND_INTERPERSONAL_V_SCALED',\n",
       "       'VINELAND_PLAY_V_SCALED', 'VINELAND_COPING_V_SCALED',\n",
       "       'VINELAND_SOCIAL_STANDARD', 'VINELAND_SUM_SCORES',\n",
       "       'VINELAND_ABC_STANDARD', 'VINELAND_INFORMANT', 'WISC_IV_VCI',\n",
       "       'WISC_IV_PRI', 'WISC_IV_WMI', 'WISC_IV_PSI', 'WISC_IV_SIM_SCALED',\n",
       "       'WISC_IV_VOCAB_SCALED', 'WISC_IV_INFO_SCALED', 'WISC_IV_BLK_DSN_SCALED',\n",
       "       'WISC_IV_PIC_CON_SCALED', 'WISC_IV_MATRIX_SCALED',\n",
       "       'WISC_IV_DIGIT_SPAN_SCALED', 'WISC_IV_LET_NUM_SCALED',\n",
       "       'WISC_IV_CODING_SCALED', 'WISC_IV_SYM_SCALED', 'EYE_STATUS_AT_SCAN',\n",
       "       'AGE_AT_MPRAGE', 'BMI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35837f6-a163-448a-859b-e3090da79e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_metadata_df = pd.read_csv(\"/blue/ruogu.fang/ryoi360/projects/fmri_vlm/results/2025_02_25_ABIDE_processing/Phenotypic_V1_0b_preprocessed1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f0b8635-ae09-47e9-93f6-3e4ec655cd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0.1\n",
      "Unnamed: 0\n",
      "SUB_ID\n",
      "X\n",
      "subject\n",
      "SITE_ID\n",
      "FILE_ID\n",
      "DX_GROUP\n",
      "DSM_IV_TR\n",
      "AGE_AT_SCAN\n",
      "SEX\n",
      "HANDEDNESS_CATEGORY\n",
      "HANDEDNESS_SCORES\n",
      "FIQ\n",
      "VIQ\n",
      "PIQ\n",
      "FIQ_TEST_TYPE\n",
      "VIQ_TEST_TYPE\n",
      "PIQ_TEST_TYPE\n",
      "ADI_R_SOCIAL_TOTAL_A\n",
      "ADI_R_VERBAL_TOTAL_BV\n",
      "ADI_RRB_TOTAL_C\n",
      "ADI_R_ONSET_TOTAL_D\n",
      "ADI_R_RSRCH_RELIABLE\n",
      "ADOS_MODULE\n",
      "ADOS_TOTAL\n",
      "ADOS_COMM\n",
      "ADOS_SOCIAL\n",
      "ADOS_STEREO_BEHAV\n",
      "ADOS_RSRCH_RELIABLE\n",
      "ADOS_GOTHAM_SOCAFFECT\n",
      "ADOS_GOTHAM_RRB\n",
      "ADOS_GOTHAM_TOTAL\n",
      "ADOS_GOTHAM_SEVERITY\n",
      "SRS_VERSION\n",
      "SRS_RAW_TOTAL\n",
      "SRS_AWARENESS\n",
      "SRS_COGNITION\n",
      "SRS_COMMUNICATION\n",
      "SRS_MOTIVATION\n",
      "SRS_MANNERISMS\n",
      "SCQ_TOTAL\n",
      "AQ_TOTAL\n",
      "COMORBIDITY\n",
      "CURRENT_MED_STATUS\n",
      "MEDICATION_NAME\n",
      "OFF_STIMULANTS_AT_SCAN\n",
      "VINELAND_RECEPTIVE_V_SCALED\n",
      "VINELAND_EXPRESSIVE_V_SCALED\n",
      "VINELAND_WRITTEN_V_SCALED\n",
      "VINELAND_COMMUNICATION_STANDARD\n",
      "VINELAND_PERSONAL_V_SCALED\n",
      "VINELAND_DOMESTIC_V_SCALED\n",
      "VINELAND_COMMUNITY_V_SCALED\n",
      "VINELAND_DAILYLVNG_STANDARD\n",
      "VINELAND_INTERPERSONAL_V_SCALED\n",
      "VINELAND_PLAY_V_SCALED\n",
      "VINELAND_COPING_V_SCALED\n",
      "VINELAND_SOCIAL_STANDARD\n",
      "VINELAND_SUM_SCORES\n",
      "VINELAND_ABC_STANDARD\n",
      "VINELAND_INFORMANT\n",
      "WISC_IV_VCI\n",
      "WISC_IV_PRI\n",
      "WISC_IV_WMI\n",
      "WISC_IV_PSI\n",
      "WISC_IV_SIM_SCALED\n",
      "WISC_IV_VOCAB_SCALED\n",
      "WISC_IV_INFO_SCALED\n",
      "WISC_IV_BLK_DSN_SCALED\n",
      "WISC_IV_PIC_CON_SCALED\n",
      "WISC_IV_MATRIX_SCALED\n",
      "WISC_IV_DIGIT_SPAN_SCALED\n",
      "WISC_IV_LET_NUM_SCALED\n",
      "WISC_IV_CODING_SCALED\n",
      "WISC_IV_SYM_SCALED\n",
      "EYE_STATUS_AT_SCAN\n",
      "AGE_AT_MPRAGE\n",
      "BMI\n",
      "anat_cnr\n",
      "anat_efc\n",
      "anat_fber\n",
      "anat_fwhm\n",
      "anat_qi1\n",
      "anat_snr\n",
      "func_efc\n",
      "func_fber\n",
      "func_fwhm\n",
      "func_dvars\n",
      "func_outlier\n",
      "func_quality\n",
      "func_mean_fd\n",
      "func_num_fd\n",
      "func_perc_fd\n",
      "func_gsr\n",
      "qc_rater_1\n",
      "qc_notes_rater_1\n",
      "qc_anat_rater_2\n",
      "qc_anat_notes_rater_2\n",
      "qc_func_rater_2\n",
      "qc_func_notes_rater_2\n",
      "qc_anat_rater_3\n",
      "qc_anat_notes_rater_3\n",
      "qc_func_rater_3\n",
      "qc_func_notes_rater_3\n",
      "SUB_IN_SMP\n"
     ]
    }
   ],
   "source": [
    "for col in preprocessed_metadata_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e05132c9-ef3c-4999-942a-fe05f7a9e5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects after stricter filtering: 714\n"
     ]
    }
   ],
   "source": [
    "motion_filtered_df = preprocessed_metadata_df[(preprocessed_metadata_df['func_mean_fd'] <= 0.2) & (preprocessed_metadata_df['func_num_fd'] < 20)]\n",
    "\n",
    "print(f\"Subjects after stricter filtering: {len(motion_filtered_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "290e81cb-20b4-4edc-9f8c-10a9f8ca6721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_metadata_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ebd4d70-7982-47f6-9b04-5da9f56575fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.116828\n",
       "1       0.322092\n",
       "2       0.127745\n",
       "3       0.128136\n",
       "4       0.070143\n",
       "          ...   \n",
       "1107    0.116186\n",
       "1108    0.140171\n",
       "1109    0.154887\n",
       "1110    0.048246\n",
       "1111    0.168913\n",
       "Name: func_mean_fd, Length: 1112, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_metadata_df[\"func_mean_fd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d39ebbd9-293f-47e7-9167-4678fe35aa7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.7534808758)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_metadata_df[\"func_fwhm\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20545cfc-fb47-4a33-a801-fe4664dd3d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5667c5b9-d64f-4c91-b38b-6b0840dde23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abide_files = glob.glob(\"/orange/ruogu.fang/ryoi360/ABIDE/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de8274fc-96af-414d-862c-2d610b4050db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abide_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7892f4-7dee-4a8a-b994-3791df45cb1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20049441-258c-4119-8e43-9a12f042236f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fmri_img = nib.load(abide_files[0])\n",
    "fmri_data = fmri_img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3182e2-e867-47fa-866a-709987278cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 73, 61, 116)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940701ed-44a5-40b4-b02e-22ee8ac70953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Voxel Size (mm): [3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Get the voxel size from the affine transformation matrix\n",
    "voxel_size = np.sqrt(np.sum(fmri_img.affine[:3, :3] ** 2, axis=0))\n",
    "print(\"Original Voxel Size (mm):\", voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b288a84-e956-413e-889d-f16ed92027fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Install Required Packages\n",
    "If you haven't installed Nipype, Nibabel, and NiLearn, do so using:\n",
    "\n",
    "bash\n",
    "Copy\n",
    "Edit\n",
    "pip install nipype nibabel nilearn numpy scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58581f4-646d-4b58-a50b-6a004fa5679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Preprocessing Steps in Python\n",
    "Step 1: Rigid Body Motion Correction\n",
    "Use SPM's Realign function via Nipype.\n",
    "Alternatively, use FSL's MCFLIRT.\n",
    "SPM12 (via Nipype)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.spm import Realign\n",
    "\n",
    "realign = Realign()\n",
    "realign.inputs.in_files = 'subject_func.nii'  # Replace with your file path\n",
    "realign.inputs.register_to_mean = True\n",
    "realign.run()\n",
    "FSL Alternative\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.fsl import MCFLIRT\n",
    "\n",
    "mcflirt = MCFLIRT()\n",
    "mcflirt.inputs.in_file = 'subject_func.nii'\n",
    "mcflirt.inputs.out_file = 'motion_corrected.nii'\n",
    "mcflirt.run()\n",
    "Step 2: Slice Timing Correction\n",
    "Adjusts for differences in slice acquisition time.\n",
    "Requires TR (repetition time) and slice order.\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.spm import SliceTiming\n",
    "\n",
    "slice_timing = SliceTiming()\n",
    "slice_timing.inputs.in_files = 'motion_corrected.nii'\n",
    "slice_timing.inputs.time_repetition = 2.0  # Set the correct TR\n",
    "slice_timing.run()\n",
    "Step 3: Normalization to MNI Space\n",
    "Warp the functional data into MNI152 template.\n",
    "Use SPM's Normalize or FSL's FLIRT/FNIRT.\n",
    "SPM Normalization\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.spm import Normalize12\n",
    "\n",
    "normalize = Normalize12()\n",
    "normalize.inputs.image_to_align = 'slice_time_corrected.nii'\n",
    "normalize.inputs.apply_to_files = ['slice_time_corrected.nii']\n",
    "normalize.inputs.jobtype = 'estwrite'  # Estimate and apply transformation\n",
    "normalize.run()\n",
    "FSL FLIRT Alternative\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nipype.interfaces.fsl import FLIRT\n",
    "\n",
    "flirt = FLIRT()\n",
    "flirt.inputs.in_file = 'slice_time_corrected.nii'\n",
    "flirt.inputs.reference = '/usr/local/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz'\n",
    "flirt.inputs.out_file = 'normalized.nii'\n",
    "flirt.run()\n",
    "Step 4: Resampling to 3×3×3 mm³\n",
    "Use NiLearn for resampling.\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nilearn.image import resample_img\n",
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(\"normalized.nii\")\n",
    "\n",
    "resampled_img = resample_img(img, target_affine=np.diag([3, 3, 3, 1]))\n",
    "nib.save(resampled_img, \"resampled_3mm.nii\")\n",
    "Step 5: Spatial Smoothing (FWHM = 6 mm)\n",
    "Apply Gaussian smoothing using NiLearn.\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nilearn.image import smooth_img\n",
    "\n",
    "smoothed_img = smooth_img(\"resampled_3mm.nii\", fwhm=6)\n",
    "smoothed_img.to_filename(\"smoothed.nii\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14084270-635f-420d-bc8e-092d69ec081e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607fa7e-49be-4e90-8af1-662dcc87ef38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda79c1-0261-40ec-a0de-e14f8945a2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68818b9c-bbed-41bc-9bf2-b310731897be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilabel_env",
   "language": "python",
   "name": "nibabel_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
